---
title: "Estudio sobre el versionado de WordPress mundial"
author: "R Team - Carlos Rivero, Pau Casaus, Iago Gallego, Ernest Costa"
date: "Mayo 2017"
output:
  html_document:
    toc: yes
  html_notebook:
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.align = 'center')
```

# Introduccion 

*WordPress* es el Sistema Gestor de Contenidos (CMS - Content Management System), más usado en Internet. Empezó como una plataforma para la publicación de Blogs pero gracias a un buen soporte y contínuas actualizaciones que mejoran  funcionalidades, usabilidad y seguridad, se ha extendido su uso para la creación de páginas web en general.
Además dispone del apoyo de la comunidad de desarrolladores que ponen a disposición infinidad de temas, plantillas y plugins.

Dentro del ranking mundial, *WordPress* es usado por el 28% de páginas web de todo el mundo, y de todas ellas, de las que usan CMS ocupa el 59% del mercado (como referencia en segundo lugar estaria Joomla con un 7%).


---

#  Objetivo de la práctica

Entre los objetivos de las actualizaciones tanto de la propia plataforma *WordPress* como de sus plugins y temas, está la de solucionas a las vulnerabilidades que se van descubriendo y publicando en cada una de sus versiones.
El objetivo de nuestro estudio es el de conocer en qué versión se encuentra cada página web de la muestra para poder identificar a cuantas vulnerabilidades está expuesta.
Realizando el análisis de datos globalmente, podemos posicionar cada país segun el estado de actualización de sus páginas *WordPress* asignando un nivel de Riesgo para cada país.

Todo ello se realiza a través de un lenguaje con enfoque estadístico llamado R.

[![Lenguaje R](./imagenes/LenguajeR.png)](https://es.wikipedia.org/wiki/R_(lenguaje_de_programaci%F3n))

#  Procedimiento

*  **Extracción de datos**: Para conseguir la lista de URLs *WordPress* con su versión y para cada versión, el listado de vulnerabilidades de cada una.
*  **Procesado con R**: Tratamos los datos para procesar y ordenar dentro de DataFrames.
*  **Graficas de resultados**: Sacamos graficas para entender los resultados de forma visual. 
*  **Conclusiones**: Explicamos las conclusiones que se pueden sacar despues del tratamiento y muestra grafica de resultados.


### Extracción de datos

Para la extracción de datos, en un primer momento se implementó un crawler con el módulo de Python: **scrapy**. Esta araña web realizaba los siguientes pasos:

 - Buscar en Google la siguiente consulta: `"index of” inurl:wp-content `. Esta búsqueda devuelve un listado de página que utilizan Wordpress.
 - Acceder resultado a resultado a la ruta `/readme.html`. En este fichero, aparece la versión de Wordpress si no ha sido modificado.
 - En el caso de mantener el readme por defecto, se realiza un parseo del html a través de **BeautifulSoup** y se extrae la versión. 
 
 El problema aparece cuando Google detecta que se está utilizando un crawler y solicita un Captcha muy difícil de bypassear, lo que nos deja con una cantidad de resultados muy inferior a la esperada.

La alternativa al crawler es el uso del servicio de **Google Custome Search Engine (CSE)** que, con una serie de modificaciones, puede utilizarse para realizar búsquedas en toda la red. 
Otro problema que plantea esta alternativa es la limitación de la versión gratuita de la API: Solo permite consultar **64 resultados por búsqueda**.   
Para evitar esta limitación se realizan diferentes búsquedas similares para poder obtener más resultados. En este caso, se utiliza la siguiente consulta modificando el campo `es` por un listado de sites disponibles:  
`“index of” inurl:wp-content site:es `.  
Así se obtienen 64 resultados por site y se pueden realizar comparativas entre los resultados de cada uno de ellos.  
  
Se han intentado utilizar otras APIs para la búsqueda de datos, pero se han encontrado los siguientes problemas en cada una de ellas:

 - **Google Web Search API**: Deprecated. 
 - **Yahoo Boss**: Discontinued.
 - **Bing Web Search API**: De pago.
 - **Faroo**: Requisitos no cumplidos para obtener una API key.



### Procesado con R

Incorporamos el fichero en formato JSON en el script de R, para convertirlo en un dataframe.
Limpiamos los resultados de la muestra que como es lógico estará **dirty**.
Quitamos las URLs repetidas, las duplicadas y eliminamos las que no hayamos podido obtener su versión. 


```{r Librerias, echo=FALSE}
# Cargando Libreria
library(wpsversionator)

if (!suppressMessages(suppressWarnings(require("jsonlite", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("jsonlite", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("RCurl", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("RCurl", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("bitops", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("bitops", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("stats", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("stats", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("base", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("base", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("dplyr", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("dplyr", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("tidyr", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("tidyr", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("googleVis", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("googleVis", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
if (!suppressMessages(suppressWarnings(require("ggplot2", quietly = T)))) {
  suppressMessages(suppressWarnings(install.packages("ggplot2", repos = "http://cran.rstudio.com/", quiet = T, dependencies = T)))
}
```

```{r CargaInicial, cache=FALSE}
# Para que la salida de Plot de Google vaya al Markdown
TotalVersionesURLPaises <- wpsversionator::cargaUrls("./data/data.json")

```

```{r cargaVulnerabilidades}
versiones <- wpsversionator::listarVersiones(TotalVersionesURLPaises)
AllVulns <- wpsversionator::cargaVulnerabilidades(versiones)
TotalVulnsVersion <- wpsversionator::totalVulnerabilidades(AllVulns, versiones)
```

```{r Tratamientodatos}
TotalVersionesURLVulnsPaises <- wpsversionator::GeneraTotalDF(TotalVersionesURLPaises)
```

### Graficas de resultados

Ahora con los dataframes preparados con los resultados calculados, podemos sacar diferentes graficas


**Tarta con el total de versiones encontradas en la muestra, ordenada por mayor aparición**

```{r Tarta_Paises, echo = TRUE, results='asis', tidy=FALSE}
plot(wpsversionator::tarta(TotalVersionesURLVulnsPaises))
```


**Grafica de barras con el total de vulnerabilidades totales en cada pais (del total de sus WordPress)**

```{r Barras_Vulns_Paises, out.width = "800px", echo = TRUE, results='asis', tidy=FALSE}
plot(wpsversionator::barras(TotalVersionesURLVulnsPaises))
```


**Top 8 de Paises con más Riesgo. Calculado según antigüedad de versiones y vulnerabilidades de cada una**


```{r Grafica_Top, echo = TRUE, results='asis', tidy=FALSE}
plot(wpsversionator::relojes(TotalVersionesURLVulnsPaises))
```

**Mapa de Paises con su Riesgo**


```{r Mapa_Vulns_Paises, echo = TRUE, results='asis', tidy=FALSE}
plot(wpsversionator::mapa(TotalVersionesURLVulnsPaises))
```


 
